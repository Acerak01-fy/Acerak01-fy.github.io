[{"title":"FlexGV系统工作原理","url":"/FlexGV%E7%B3%BB%E7%BB%9F%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/FlexGV%E7%B3%BB%E7%BB%9F%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/","content":"FlexGV系统工作原理\nFlexGV系统架构\n\n各部分功能详解：租户侧：1.GPU API Wrapper （GPU API 封装器）+ Training Job（训练任务）：&emsp;GPU API wrapper和Training job为一个模块，并且向GPU Proxy发送Resorce request （资源请求）。&emsp;GPU API wrapper将拦截用户的API（比如PyTorch这些训练框架，而这些框架要使用GPU来训练的话，会调用CUDA API）把API打包成网络请求，发送给GPU Service让它执行。\n2.GPU Proxy&emsp;拦截一开始程序运行的资源申请，并向集群那边申请资源。即将资源请求发送给Resource Dispatcher。后台挂着就行。为什么不直接让用户侧发送资源请求到资源调度器而是设计一个Proxy，是为了缓解Resource Dispatcher的压力，因为一个作业有可能需要多块GPU。&emsp;通俗来讲：就是首先用户侧首先向GPU Proxy问哪些是可用的GPU，然后GPU Proxy就帮忙找Resource Dispatcher问哪些可用的GPU，然后拿到了再返回给租户这边的应用程序\n服务商侧：3.Resource Dispatcher（资源调度器）&emsp;负责在多个任务或用户之间分配和调度 GPU 资源。其下属还有一个redis界面，查看各个数据库的GPU情况，并且将所有GPU资源整合到一起，形成资源池。也可以理解为将多个GPU融合成为一个GPU。后台挂着就行。\n4.GPU Service&emsp;首先将GPU的资源信息注册进Resource Dispatcher的数据库中。并且和租户侧的API Wrapper进行API交互。\n左右两侧组件的关系和作用&emsp;左侧是针对 API请求，右侧是针对资源申请请求。资源申请是拿GPU，发生在作业运行前期的过程；API请求是发生在训练过程当中，作业与GPU交互。只是作用的时间点不同但是都是协同才能完成整个操作。相当于右侧是先获取宏观的GPU资源，左侧是获取微观的训练作业交互。\n","categories":["项目"],"tags":["GPu"]},{"title":"GPU虚拟化笔记","url":"/GPU%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AC%94%E8%AE%B0/index/","content":"\n一、样例demo透析：旨在透过简单的demo样例刨析，FlexGV系统的工作原理。demo地址：https://github.com/J-StrawHat/cuda-hook-demo/blob/master/build.sh\n首先什么是解释一下什么是CMake项目：CMake 是一个 跨平台的构建系统，用于生成编译配置文件（如 Makefile、Visual Studio 解决方案等）。CMake 本身不会编译代码，但它会为不同的平台和编译器生成适合的构建配置文件，从而让开发者可以使用 make 或 ninja 等工具完成编译。\n一个 CMake 项目，通常指的是使用 CMake 构建的 C&#x2F;C++ 项目，其中包含：\nCMakeLists.txt（CMake 配置文件）\n源代码（.cpp、.h 等）\nCMake 生成的构建文件（Makefile、Visual Studio 解决方案 等）\n\nCMake 不是编译器，它用于生成编译配置文件（如 Makefile）。CMake 项目 是指使用 CMakeLists.txt 组织的 C&#x2F;C++ 项目。使用 CMake 的好处：\n跨平台：支持 Linux、Windows、MacOS。\n自动查找依赖（如 find_package(OpenCV)）。\n支持构建动态/静态库。\n\n你可以把 CMake 理解为 “项目构建的指挥官”，它负责告诉编译器怎么编译你的项目。\n1.build.sh （主要用于构建编译系统，提前创建好如何编译和处理文件。）#!/bin/bashset -o errexitset -o pipefailset -o nounsetecho_cmd() &#123;    echo $1    $1&#125;WORK_PATH=$(cd $(dirname $0) &amp;&amp; pwd) &amp;&amp; cd $WORK_PATHcompile() &#123;    isSample=$1    if [[ $isSample == 1 ]]; then        cmakeFlag=&quot;-DBUILD_SAMPLE=ON&quot;    else        cmakeFlag=&quot;-DBUILD_HOOK=ON&quot;    fi    echo_cmd &quot;rm -rf build&quot;    echo_cmd &quot;mkdir build&quot;    echo_cmd &quot;cd build&quot;    echo_cmd &quot;cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=$WORK_PATH/out $cmakeFlag -DCMAKE_SKIP_RPATH=ON ..&quot;    echo_cmd &quot;make -j2&quot;    echo_cmd &quot;make install&quot;    echo_cmd &quot;cd $WORK_PATH&quot;&#125;echo_cmd &quot;rm -rf out&quot;# build for hookcompile 0# build for samplecompile 1\n这个脚本的主要流程是：\n确保所有命令在当前脚本所在目录下执行。清除 out 目录，确保干净环境。定义 compile 函数，接收 0 或 1 选择不同的 cmake 选项。先编译 hook 版本（-DBUILD_HOOK&#x3D;ON）。再编译 sample 版本（-DBUILD_SAMPLE&#x3D;ON）。这样可以确保 hook 和 sample 版本都被正确编译和安装。\n2.cuda_hook.cpp &#x2F;&#x2F;这里相当于拦截层这个文件主要用于创建cuda_hook，来截取用户的请求也就是CUDA_API。逻辑流程就是在执行用户的需求时也就是执行main.cu文件的时候，首先在终端通过LD_PRELOAD 将main.cu加载到对应的cuda_hook所在的目录里，在main.cu执行的时候，LD_PRELOAD&#x3D;.&#x2F;libhook.so，系统在 动态链接库解析阶段 发现 libhook.so 里提供了 cudaMalloc，所以会优先调用 libhook.so 里的 cudaMalloc。\nLD_PRELOAD原理：预加载一个共享库，在动态链接时优先使用自己的 cudaMalloc。不影响 原始 CUDA 运行时库（只是拦截）\n在 LD_PRELOAD 机制下：\n1.程序启动时，LD_PRELOAD 里的 libhook.so 先被加载。\n2.cudaMalloc 被调用时，动态链接器优先使用 libhook.so 里的 cudaMalloc。\n3.如果 libhook.so 里的 cudaMalloc 需要调用原始 cudaMalloc，它会用 dlsym(RTLD_NEXT, &quot;cudaMalloc&quot;) 找到 CUDA 运行时库里的真正 cudaMalloc 并调用它。这里可以实现拦截和真实函数的衔接。\n\n#include &lt;stdio.h&gt;#include &lt;cuda_runtime.h&gt;#include &lt;dlfcn.h&gt;// 声明原始的 cudaMalloc 函数类型typedef cudaError_t (*cudaMalloc_t)(void **devPtr, size_t size);// 获取原始 cudaMalloc 函数指针static cudaMalloc_t real_cudaMalloc = nullptr;// 自定义的 cudaMalloc 拦截函数cudaError_t cudaMalloc(void **devPtr, size_t size) &#123;    if (!real_cudaMalloc) &#123;        // 动态加载原始的 cudaMalloc 函数        real_cudaMalloc = (cudaMalloc_t) dlsym(RTLD_NEXT, &quot;cudaMalloc&quot;);        //dlsym() 是 dlfcn.h 提供的一个函数，用于在共享库中查找符号（函数地址）。RTLD_NEXT 表示 查找下一个同名符号，即查找 CUDA 运行时库中的 原始 cudaMalloc。如果 dlsym() 失败（找不到原始 cudaMalloc），则输出错误信息，并返回 cudaErrorUnknown。        if (!real_cudaMalloc) &#123;            fprintf(stderr, &quot;[hook] Error: unable to find real cudaMalloc\\n&quot;);            return cudaErrorUnknown;        &#125;    &#125;    // 输出日志：记录每次 cudaMalloc 调用的大小    printf(&quot;[hook] Intercepted cudaMalloc call: size = %zu bytes\\n&quot;, size);    // 调用原始的 cudaMalloc    return real_cudaMalloc(devPtr, size);&#125;\n\n3.main.cu &#x2F;&#x2F;这里相当于用户层#include &lt;cstdio&gt;#include &lt;cassert&gt;#include &lt;cuda_runtime.h&gt;int main() &#123;    void *devPtr;    cudaError_t err = cudaMalloc(&amp;devPtr, 1024);    if (err != cudaSuccess) &#123;        printf(&quot;[main] cudaMalloc failed: %s\\n&quot;, cudaGetErrorString(err));    &#125;    else &#123;        printf(&quot;[main] cudaMalloc succeeded\\n&quot;);        assert(cudaFree(devPtr) == cudaSuccess);    &#125;    return 0;&#125;\n4.CMakeLists.txtCMakeLists.txt 是 CMake 的配置文件，它定义了 如何构建（编译、链接、安装）一个 C&#x2F;C++ 项目。\nCMake 是一个跨平台的 构建工具，可以生成适用于不同编译器（GCC、Clang、MSVC）和构建系统（Makefile、Ninja、Visual Studio）的项目文件。CMakeLists.txt 主要用于 描述源码结构、指定编译选项、链接库 等。\ncmake_minimum_required(VERSION 3.12)project(CudaHook)set (CMAKE_POSITION_INDEPENDENT_CODE ON)set (CMAKE_C_FLAGS &quot;-std=c17&quot;)set (CMAKE_C_FLAGS_DEBUG &quot;$ENV&#123;CFLAGS&#125; -O0 -g2 -ggdb -DHOOK_BUILD_DEBUG&quot;)set (CMAKE_C_FLAGS_RELEASE &quot;$ENV&#123;CFLAGS&#125; -O3&quot;)set (CMAKE_CXX_FLAGS &quot;-std=c++17&quot;)set (CMAKE_CXX_FLAGS_DEBUG &quot;$ENV&#123;CXXFLAGS&#125; -O0 -g2 -ggdb -DHOOK_BUILD_DEBUG&quot;)set (CMAKE_CXX_FLAGS_RELEASE &quot;$ENV&#123;CXXFLAGS&#125; -O3&quot;)set (CMAKE_SHARED_LINKER_FLAGS &quot;-s -Wl,--exclude-libs,ALL&quot;)set (CMAKE_EXE_LINKER_FLAGS &quot;-Wl,--as-needed&quot;)# 添加一个选项来决定是否编译拦截库或者 main 程序option(BUILD_SAMPLE &quot;Build the sample main program&quot; OFF)option(BUILD_HOOK &quot;Build the CUDA hook library&quot; OFF)# 如果选择编译拦截库if(BUILD_HOOK)    find_package(CUDA REQUIRED)    include_directories($&#123;CUDA_INCLUDE_DIRS&#125;)    add_library(cuda_hook SHARED cuda_hook.cpp)    set_target_properties(cuda_hook PROPERTIES POSITION_INDEPENDENT_CODE ON)    target_link_libraries(cuda_hook $&#123;CUDA_LIBRARIES&#125; dl)    install(TARGETS cuda_hook LIBRARY DESTINATION lib64)endif()# 如果选择编译 main 程序if(BUILD_SAMPLE)    find_package(CUDA REQUIRED)     unset (CUDA_USE_STATIC_CUDA_RUNTIME CACHE)    option (CUDA_USE_STATIC_CUDA_RUNTIME OFF)    include_directories($&#123;CUDA_INCLUDE_DIRS&#125;)    set (CUDA_NVCC_FLAGS &quot;$&#123;CUDA_NVCC_FLAGS&#125; -std=c++17&quot;)    cuda_add_executable(main main.cu)    target_link_libraries(main $&#123;CUDA_LIBRARIES&#125; dl)    install(TARGETS main RUNTIME DESTINATION .)endif()\n","categories":["项目"],"tags":["GPu"]}]